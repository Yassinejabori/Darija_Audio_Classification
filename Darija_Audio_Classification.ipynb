{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=1></a>\n# 1. Importing libraries  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio, display\nimport IPython\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom tensorflow import keras \nfrom tensorflow.keras.utils import to_categorical\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:20:19.993553Z","iopub.execute_input":"2022-01-19T21:20:19.993798Z","iopub.status.idle":"2022-01-19T21:20:20.001264Z","shell.execute_reply.started":"2022-01-19T21:20:19.993773Z","shell.execute_reply":"2022-01-19T21:20:20.000239Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<a id=2></a>\n# 2. Loading data","metadata":{}},{"cell_type":"code","source":"# Let's define the train and the test paths\nmain_path = \"/kaggle/input/moroccan-darija-trigger-word-classification-ed-2/\"\ntrain_path = main_path + \"data/train/\"\ntest_path = main_path + \"data/test/\"","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:18:28.583464Z","iopub.execute_input":"2022-01-19T21:18:28.583781Z","iopub.status.idle":"2022-01-19T21:18:28.587211Z","shell.execute_reply.started":"2022-01-19T21:18:28.583758Z","shell.execute_reply":"2022-01-19T21:18:28.586651Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Loading .csv files \ndf_train = pd.read_csv(main_path + \"train.csv\")\ndf_test = pd.read_csv(main_path + \"test.csv\")\nsubmission_file = pd.read_csv(main_path + \"sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:18:31.870567Z","iopub.execute_input":"2022-01-19T21:18:31.870784Z","iopub.status.idle":"2022-01-19T21:18:31.921823Z","shell.execute_reply.started":"2022-01-19T21:18:31.870762Z","shell.execute_reply":"2022-01-19T21:18:31.921370Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Let's take a look to our training set**","metadata":{}},{"cell_type":"code","source":"df_train.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:18:34.972751Z","iopub.execute_input":"2022-01-19T21:18:34.973073Z","iopub.status.idle":"2022-01-19T21:18:34.993533Z","shell.execute_reply.started":"2022-01-19T21:18:34.973050Z","shell.execute_reply":"2022-01-19T21:18:34.993104Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"filePath = train_path +'k1xcfnu6vwm3p8y5lior2.wav'\nIPython.display.Audio(filePath)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:21:49.664027Z","iopub.execute_input":"2022-01-19T21:21:49.665159Z","iopub.status.idle":"2022-01-19T21:21:49.688091Z","shell.execute_reply.started":"2022-01-19T21:21:49.665108Z","shell.execute_reply":"2022-01-19T21:21:49.687094Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of training set: \", df_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:21:52.524006Z","iopub.execute_input":"2022-01-19T21:21:52.524830Z","iopub.status.idle":"2022-01-19T21:21:52.529385Z","shell.execute_reply.started":"2022-01-19T21:21:52.524761Z","shell.execute_reply":"2022-01-19T21:21:52.528933Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"<a id=4></a>\n# 3. Features Extraction","metadata":{}},{"cell_type":"code","source":"sound1, _ = librosa.load(filePath,res_type=\"kaiser_fast\", duration=2.5 , offset=0.5)\nmfccs = librosa.feature.mfcc(y=sound1, sr=44100, n_mfcc=30)\nprint(mfccs.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:33:37.558903Z","iopub.execute_input":"2022-01-19T21:33:37.559272Z","iopub.status.idle":"2022-01-19T21:33:37.607961Z","shell.execute_reply.started":"2022-01-19T21:33:37.559247Z","shell.execute_reply":"2022-01-19T21:33:37.607080Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"librosa.display.specshow(mfccs, x_axis='time')\nplt.colorbar()\nplt.title('mfcc')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:21:55.799742Z","iopub.execute_input":"2022-01-19T21:21:55.800559Z","iopub.status.idle":"2022-01-19T21:21:56.026338Z","shell.execute_reply.started":"2022-01-19T21:21:55.800531Z","shell.execute_reply":"2022-01-19T21:21:56.025344Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def data_preparation(df, n, mfcc, path):\n\n    X = np.zeros(shape=(df.shape[0], n, 216, 1))\n    input_length = sample_rate*audio_duration\n    \n    counter = 0\n    \n    for fileName in tqdm(df.id):\n        filePath = path + str(fileName) + \".wav\"\n        soundData, _ = librosa.load(filePath, sr=sample_rate, res_type=\"kaiser_fast\",duration=2.5 , offset=0.5)\n        \n        # Random Padding/ offset    \n        if len(soundData) > input_length:\n            max_offset = len(soundData) - input_length\n            offset = np.random.randint(max_offset)\n            soundData = soundData[offset:int(input_length+offset)]\n        else:\n            if input_length > len(soundData):\n                max_offset = input_length - len(soundData)\n                offset = np.random.randint(max_offset)\n            else:\n                offset = 0\n                \n            soundData = np.pad(soundData, (offset, int(input_length) - len(soundData) - offset), \"constant\")\n            \n        # Features Extraction\n        if mfcc == 1:\n            MFCC = librosa.feature.mfcc(soundData, sr=sample_rate, n_mfcc=n_mfcc)\n            MFCC = np.expand_dims(MFCC, axis=-1)\n            X[counter,] = MFCC\n        \n        counter +=1\n            \n    return X\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:22:22.337907Z","iopub.execute_input":"2022-01-19T21:22:22.338331Z","iopub.status.idle":"2022-01-19T21:22:22.347647Z","shell.execute_reply.started":"2022-01-19T21:22:22.338307Z","shell.execute_reply":"2022-01-19T21:22:22.346602Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"sample_rate=44100\naudio_duration=2.5\nn_mfcc = 30\n\n# Features Extraction (MFCCS)\nX_mfccs = data_preparation(df_train, n_mfcc, 1, train_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:25:28.835514Z","iopub.execute_input":"2022-01-19T21:25:28.835892Z","iopub.status.idle":"2022-01-19T21:25:34.539881Z","shell.execute_reply.started":"2022-01-19T21:25:28.835867Z","shell.execute_reply":"2022-01-19T21:25:34.539216Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Concatenate X_mfccs, X_WnAug, W_SPAug, W_SfAug\nX = X_mfccs\ny = df_train['label'].values\ny = to_categorical(y)\ny = np.concatenate([y])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:25:44.902745Z","iopub.execute_input":"2022-01-19T21:25:44.902994Z","iopub.status.idle":"2022-01-19T21:25:44.907428Z","shell.execute_reply.started":"2022-01-19T21:25:44.902969Z","shell.execute_reply":"2022-01-19T21:25:44.906685Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# 2D matrix of 30 MFCC bands by 216 audio length.\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:25:52.565422Z","iopub.execute_input":"2022-01-19T21:25:52.565867Z","iopub.status.idle":"2022-01-19T21:25:52.570531Z","shell.execute_reply.started":"2022-01-19T21:25:52.565840Z","shell.execute_reply":"2022-01-19T21:25:52.569725Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Features Extraction\nX_test_mfccs = data_preparation(df_test, n_mfcc, 1, test_path)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:25:56.758230Z","iopub.execute_input":"2022-01-19T21:25:56.758449Z","iopub.status.idle":"2022-01-19T21:26:00.013424Z","shell.execute_reply.started":"2022-01-19T21:25:56.758426Z","shell.execute_reply":"2022-01-19T21:26:00.012857Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X\n                                                    , y\n                                                    , test_size=0.1\n                                                    , shuffle=True\n                                                    , random_state=43\n                                                   )\nprint(f'training set : {X_train.shape} , validation set :{X_valid.shape}, test set : {X_test_mfccs.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:26:02.056168Z","iopub.execute_input":"2022-01-19T21:26:02.057395Z","iopub.status.idle":"2022-01-19T21:26:02.066969Z","shell.execute_reply.started":"2022-01-19T21:26:02.057355Z","shell.execute_reply":"2022-01-19T21:26:02.065678Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Normalization \nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\nX_valid = (X_valid - mean)/std\nX_test = (X_test_mfccs - mean)/std","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:26:11.515889Z","iopub.execute_input":"2022-01-19T21:26:11.516113Z","iopub.status.idle":"2022-01-19T21:26:11.528927Z","shell.execute_reply.started":"2022-01-19T21:26:11.516089Z","shell.execute_reply":"2022-01-19T21:26:11.527794Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"<a id = 5></a>\n# 4. Modeling ","metadata":{}},{"cell_type":"code","source":"from keras import losses, models\nfrom tensorflow.keras.optimizers import Adam \nfrom keras.activations import relu, softmax\nfrom keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout,\n                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation, Input, Dense)\nfrom keras.models import Sequential, Model","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:26:45.136522Z","iopub.execute_input":"2022-01-19T21:26:45.136780Z","iopub.status.idle":"2022-01-19T21:26:45.143299Z","shell.execute_reply.started":"2022-01-19T21:26:45.136751Z","shell.execute_reply":"2022-01-19T21:26:45.142575Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\ndef convNet_model(input_shape):\n    \n    input_ = Input(shape=input_shape)  #2D matrix of 30 MFCC bands by 216 audio length.\n    x = Convolution2D(32, (3,3), padding=\"same\")(input_)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Convolution2D(64, (3,3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n    \n    x = Convolution2D(128, (3,3), padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = MaxPool2D()(x)\n    x = Dropout(rate=0.2)(x)\n\n    x = Flatten()(x)\n    x = Dense(256)(x)\n    x = Dropout(rate=0.2)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    \n    out = Dense(2, activation='softmax')(x)\n    model = Model(inputs=input_, outputs=out)\n    \n    \n    model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['acc'])\n    \n    return model\n\n\ninput_shape = X[0].shape\nmodel = convNet_model(input_shape)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:27:07.463489Z","iopub.execute_input":"2022-01-19T21:27:07.463896Z","iopub.status.idle":"2022-01-19T21:27:07.735654Z","shell.execute_reply.started":"2022-01-19T21:27:07.463863Z","shell.execute_reply":"2022-01-19T21:27:07.734466Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"model_history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                          batch_size=8, verbose = 2, shuffle=True, epochs=50)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-01-19T21:27:19.721065Z","iopub.execute_input":"2022-01-19T21:27:19.721360Z","iopub.status.idle":"2022-01-19T21:28:14.228590Z","shell.execute_reply.started":"2022-01-19T21:27:19.721327Z","shell.execute_reply":"2022-01-19T21:28:14.227329Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def plot_loss_function(history):\n    \"train and validation loss\"\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n    \nplot_loss_function(model_history)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:30:20.294715Z","iopub.execute_input":"2022-01-19T21:30:20.294964Z","iopub.status.idle":"2022-01-19T21:30:20.467985Z","shell.execute_reply.started":"2022-01-19T21:30:20.294936Z","shell.execute_reply":"2022-01-19T21:30:20.466440Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test).argmax(axis=1)\npredictions","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:30:34.674284Z","iopub.execute_input":"2022-01-19T21:30:34.674536Z","iopub.status.idle":"2022-01-19T21:30:34.993702Z","shell.execute_reply.started":"2022-01-19T21:30:34.674512Z","shell.execute_reply":"2022-01-19T21:30:34.992059Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#0 if the trigger word is \"yallahbda\" and 1 if it is \"safi7bess\".\ni = 72\nprint(\"prediction:\",predictions[i])","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:30:56.772784Z","iopub.execute_input":"2022-01-19T21:30:56.773298Z","iopub.status.idle":"2022-01-19T21:30:56.779624Z","shell.execute_reply.started":"2022-01-19T21:30:56.773271Z","shell.execute_reply":"2022-01-19T21:30:56.778642Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"submission_file['label'] = predictions\nsubmission_file.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:31:12.675987Z","iopub.execute_input":"2022-01-19T21:31:12.676273Z","iopub.status.idle":"2022-01-19T21:31:12.687934Z","shell.execute_reply.started":"2022-01-19T21:31:12.676249Z","shell.execute_reply":"2022-01-19T21:31:12.686305Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"submission_file.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T21:31:14.355666Z","iopub.execute_input":"2022-01-19T21:31:14.356771Z","iopub.status.idle":"2022-01-19T21:31:14.365040Z","shell.execute_reply.started":"2022-01-19T21:31:14.356715Z","shell.execute_reply":"2022-01-19T21:31:14.364469Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}